# -*- coding: utf-8 -*-
"""
Generate settings and wiring JSON files to be used in the Megazord pipeline.

Settings JSON file
------------------------
SPIKE SORTER
    Which spike sorter SpikeInterface should use, default is Kilosort 2.5, for options see:
    https://spikeinterface.readthedocs.io/en/latest/modules/sorters.html#supported-spike-sorters
IDENTIFIER 
    An optional string which can be used to identify spike sorting runs with different settings
    Will be appended to the name of the output directory
DATA_FOLDER 
    Path to the top-level data folder (make sure to use \\ when on Windows machines)
USE_DOCKER
    Whether to use Docker while running the spike sorting or using a local installation of Kilosort
COMPRESS_RAW_DATA
    Whether to compress the raw bin files
N_CORES
    How many CPU cores to use (default is -1 which is all of them)
    
NIDQ wiring JSON file
------------------------
SYSTEM
    Should not be changed from 3B (otherwise known as 1.0). Currently Megazord only supports 
    Neuropixel 1.0
SYNC_WIRING_DIGITAL
    Dictionary with all the digital synchronization channels on the BNC breakout box that should be
    extracted and timestamped. One of these channels should be the square wave sync pulse from 
    the PXI chassis, in this example this is channel number 3.
SYNC_WIRING_ANALOG
    Dictionary with the wiring of any analog inputs that should be synchronized with the recording.
    
Probe wiring JSON file
------------------------
Should not be changed

Created on Mon Dec 4 2023 by Guido Meijer
"""

import json
from spikeinterface.sorters import get_default_sorter_params
from pathlib import Path


def main():

    # Get paths to where to save the configuration files (in the repository)
    project_root = Path(__file__).parent.parent.parent
    if not (project_root / 'config').is_dir():
        (project_root / 'config').mkdir()
    settings_file = project_root / 'config' / 'settings.json'
    bombcell_file = project_root / 'config' / 'bombcell_params.json'
    ibl_qc_file = project_root / 'config' / 'ibl_qc_params.json'
    unitrefine_file = project_root / 'config' / 'unitrefine_params.json'
    wiring_dir = project_root / 'config' / 'wiring'
    sorting_dir = project_root / 'config' / 'sorter_params'
    
    # Settings
    if settings_file.is_file():
        print(f'\nConfiguration file already exists at {settings_file}')
    else:
        
        # Generate example settings JSON file
        settings_dict = {
            "SPIKE_SORTER": "kilosort4",            # spike sorter to use  
            "IDENTIFIER": "",                       # text to append to this spike sorting run
            "DATA_FOLDER": "C:\\path\\to\\data",    # path to the folder containing the data
            "SINGLE_SHANK": "car_local",            # options: car_global, car_local, destripe
            "MULTI_SHANK": "car_local",             # options: car_global, car_local, destripe
            "LOCAL_RADIUS": (40, 200),              # only for car_local: annulus of channels to subtract
            "PEAK_THRESHOLD": 0.0025,               # threshold of peak detection for high-freq noise
            "USE_NIDAQ": True,                      # whether you use a BNC breakout box
            "USE_DOCKER": False,                    # whether spike sorting should be run in a docker
            "COMPRESS_RAW_DATA": True,              # whether to compress raw data
            "COMPRESSION": "zarr",                  # compression options: zarr or mtscomp
            "NWB_EXPORT": False,                    # whether to export the spike sorted data as NWB
            "N_CORES": -1                           # how many CPU's to use (-1 is all)
        }
        with open(settings_file, 'w') as outfile:
            outfile.write(json.dumps(settings_dict, indent=4))
        print(f'\nExample configuration file generated at {settings_file}')
        
    # Bombcell
    if bombcell_file.is_file():
        print(f'\nBombcell param file already exists at {bombcell_file}')
    else:
        
        # Generate example settings JSON file
        bombcell_dict = {
            "extractRaw": True,
            "detrendWaveform": True,
            "computeTimeChunks": False,
            "computeDrift": False,
            "maxNPeaks": 2,  
            "maxNTroughs": 1,
            "minWvDuration": 100,
            "maxWvDuration": 1150,
            "minSpatialDecaySlopeExp": 0.01,
            "maxSpatialDecaySlopeExp": 0.1,
            "maxWvBaselineFraction": 0.3,
            "maxScndPeakToTroughRatio_noise": 0.8,
            "maxMainPeakToTroughRatio_nonSomatic": 0.8,
            "maxPeak1ToPeak2Ratio_nonSomatic": 3,
            "deltaTimeChunk": 360,
            "maxPercSpikesMissing": 20,
            "maxRPVviolations": 0.1,
            "minNumSpikes": 300,
            "maxPercSpikesMissing": 20,
            "minPresenceRatio": 0.7,
            "maxDrift": 100,
            "minAmplitude": 40,
            "minSNR": 5,
            "isoDmin": 20,
            "lratioMax": 0.3
        }
        with open(bombcell_file, 'w') as outfile:
            outfile.write(json.dumps(bombcell_dict, indent=4))
        print(f'\nDefault Bombcell param file generated at {bombcell_file}')
    
    # IBL QC params
    if ibl_qc_file.is_file():
        print(f'\nIBL QC param file already exists at {ibl_qc_file}')
    else:
        
        # Generate example settings JSON file
        ibl_dict = {
            "acceptable_contamination": 10,
            "RPmax_confidence": 90,
            "noise_cutoff": dict(quantile_length=.25, n_bins=100, nc_threshold=5, percent_threshold=0.10),
            "med_amp_thresh_uv": 50
        }
        with open(ibl_qc_file, 'w') as outfile:
            outfile.write(json.dumps(ibl_dict, indent=4))
        print(f'\nDefault IBL QC param file generated at {ibl_qc_file}')
        
    # UnitRefine params
    if unitrefine_file.is_file():
        print(f'\nUnitRefine file already exists at {unitrefine_file}')
    else:
        
        # Generate example settings JSON file
        unitrefine_dict = {
            "noise_classification": False,
            "sua_classifier": "AnoushkaJain3/sua_mua_classifier_lightweight"
        }
        with open(unitrefine_file, 'w') as outfile:
            outfile.write(json.dumps(unitrefine_dict, indent=4))
        print(f'\nDefault UnitRefine param file generated at {unitrefine_file}')
            
    # Wiring files
    if wiring_dir.is_dir():
        print(f'\nDirectory with wiring files already exists at {wiring_dir}')
    else:
        
        # NIDQ wiring JSON file
        nidq_wiring_dict = {
            "SYSTEM": "3B",
            "SYNC_WIRING_DIGITAL": {
                "P0.0": "imec_sync",
                "P0.1": "lick_detector",
                "P0.2": "camera"
            },
            "SYNC_WIRING_ANALOG": {
                "AI0": "breathing_sensor"
            }
        }
        
        # Neuropixel probe wiring JSON file
        probe_wiring_dict = {
            "SYSTEM": "3B",
            "SYNC_WIRING_DIGITAL": {
                "P0.6": "imec_sync"
            }
        }
        
        # Save example wiring configuration files to repo dir
        wiring_dir.mkdir()
        with open(wiring_dir / 'nidq.wiring.json', 'w') as outfile:
            outfile.write(json.dumps(nidq_wiring_dict, indent=4))
        with open(wiring_dir / '3B.wiring.json', 'w') as outfile:
            outfile.write(json.dumps(probe_wiring_dict, indent=4))
            
        print(f'\nExample wiring files generated in {wiring_dir}')
        
    # Spike sorter parameter files
    if sorting_dir.is_dir():
        print(f'\nSpike sorter parameter files already exist in {sorting_dir}')
    else:
        
        # Get default sorter params
        sorting_dir.mkdir()
        for sorter in ['kilosort2_5', 'kilosort3', 'kilosort4', 'pykilosort']:
            
            # Save to disk
            sorter_params = get_default_sorter_params(sorter)
            with open(sorting_dir / f'{sorter}_params.json', 'w') as outfile:
                outfile.write(json.dumps(sorter_params, indent=4))
        print(f'\nDefault settings for spike sorters generated in {sorting_dir}')
        
        
if __name__ == "__main__":
    main()
        
        
